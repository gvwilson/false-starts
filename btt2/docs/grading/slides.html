<!DOCTYPE html>
<html lang="en">
  <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="repo" content="https://github.com/gvwilson/btt">
  <link rel="icon" type="image/x-icon" href="../favicon.ico">
  <title>Building Tech Together: Grading</title>
  <link rel="stylesheet" href="../tango.css">
<link rel="stylesheet" href="../mccole.css">

<link rel="stylesheet" href="../slides.css">
<script src="../slides.js" defer></script>


  <script>
  MathJax = {
    tex: {
      inlineMath: [['\\(', '\\)']]
    }
  };
</script>
<script
  type="text/javascript"
  id="MathJax-script"
  async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>

  

</head>

  <body>

<p>
  <a href="">Building Tech Together</a>
</p>
<h1>Grading</h1>

<hr>

<h2>Goals</h2>
<ul>
<li>Many organizations focus on <em>outputs</em> rather than on <em>outcomes</em> <span class="bib-ref">[<a class="bib-ref" href="../bib/#Perri2018">Perri2018</a>]</span><ul>
<li>&ldquo;What we did&rdquo; is easier to measure than &ldquo;what we achieved&rdquo;</li>
</ul>
</li>
<li>Equivalent mistake in a project course is to measure progress by how much code you have written
    rather than by comparing your work to the grading scheme</li>
<li>Doesn&rsquo;t mean you should only do things that are going to show up on your transcript</li>
<li>But keep in mind that your actual product isn&rsquo;t your software:
    it&rsquo;s your grade</li>
</ul>
<hr />
<h2>What Does &ldquo;Productive&rdquo; Mean?</h2>
<ul>
<li><span class="bib-ref">[<a class="bib-ref" href="../bib/#Sadowski2019a">Sadowski2019a</a>]</span>: &ldquo;it&rsquo;s hard to measure&rdquo; and &ldquo;it depends&rdquo;</li>
<li><span class="bib-ref">[<a class="bib-ref" href="../bib/#Noda2023">Noda2023</a>]</span> identified three factors</li>
</ul>
<dl>
<dt>Rapid feedback</dt>
<dd>Long delays between doing things and knowing how well they were done
causes frustration and errors.</dd>
<dt>Cognitive load (Chapter&nbsp;2)</dt>
<dd>If we have to pay attention to too many things,
we can&rsquo;t keep track of any of them.</dd>
<dt>Flow state</dt>
<dd>Being immersed in a problem is pleasurable.</dd>
</dl>
<hr />
<h2>Thriving</h2>
<ul>
<li><span class="bib-ref">[<a class="bib-ref" href="../bib/#Hicks2023">Hicks2023</a>]</span>: developers are most productive when they&rsquo;re thriving</li>
<li>Agency<ul>
<li>Has a voice in how their contributions are measured</li>
<li>Able to voice disagreement with team definitions of success</li>
</ul>
</li>
<li>Motivation &amp; Self-Efficacy<ul>
<li>Motivated when working on code at work</li>
<li>Can see tangible progress most of the time</li>
<li>Is working on the type of code work they want to work on</li>
<li>Is confident they will solve their problems even when work is unexpectedly difficult</li>
</ul>
</li>
<li>Learning Culture<ul>
<li>Learning new skills as a developer</li>
<li>Able to share the things they learn at work</li>
</ul>
</li>
<li>Support and Belonging<ul>
<li>Supported to grow, learn, and make mistakes by their team</li>
<li>Agrees they are accepted for who they are by their team</li>
</ul>
</li>
</ul>
<hr />
<!--# class="aside" -->

<h2>Weigh and Measure</h2>
<ul>
<li>Degrees have three purposes:<ol>
<li>Broaden your mind</li>
<li>Train you to be employable</li>
<li>Give you and future employers a sense of what you can do</li>
</ol>
</li>
<li>Grades are inaccurate, frequently biased, and foster a zero-sum world view</li>
<li>Many people are working on alternatives <span class="bib-ref">[<a class="bib-ref" href="../bib/#Blum2020">Blum2020</a>]</span></li>
<li>But everything better requires more resources than most societies are willing to invest
    <span class="bib-ref">[<a class="bib-ref" href="../bib/#Partanen2011">Partanen2011</a>, <a class="bib-ref" href="../bib/#Sahlberg2015">Sahlberg2015</a>]</span></li>
</ul>
<hr />
<h2>Where Do Grades Come From?</h2>
<dl>
<dt>The software you produce.</dt>
<dd>Does it build and run?
Does it meet requirements (if any have been given)?
Is the source code readable?
Is it efficient?</dd>
<dt>Other deliverables.</dt>
<dd>E.g.,
a retrospective report (<span class="fixme">see&nbsp;FIXME</span>),
a demo (<span class="fixme">see&nbsp;FIXME</span>),
or the final state of the project (<span class="fixme">see&nbsp;FIXME</span>).</dd>
<dt>A final exam.</dt>
<dd>May focus on theory
(&ldquo;Describe the four main functions of Quality Assurance…&rdquo;)
but instructors may ask questions to test your understanding of <em>your</em> project
to determine who actually did the work and who was hitchhiking (<span class="fixme">see&nbsp;FIXME</span>).</dd>
</dl>
<hr />
<h2>Invisible Work</h2>
<ul>
<li>Instructors often want to assess the process you followed (<span class="fixme">see&nbsp;FIXME</span>)</li>
<li>But they can&rsquo;t watch over your shoulder while you&rsquo;re working</li>
<li>So all they can grade is artifacts<ul>
<li>Code commits (<span class="fixme">see&nbsp;FIXME</span>)</li>
<li>Issues filed (<span class="fixme">see&nbsp;FIXME</span>)</li>
<li>Status reports</li>
</ul>
</li>
<li>Often undervalues <strong>invisible work</strong> <span class="bib-ref">[<a class="bib-ref" href="../bib/#Daniels1987">Daniels1987</a>]</span><ul>
<li>Our definition of what counts as &ldquo;work&rdquo; ties closely to
    &ldquo;things that high-status people do&rdquo;</li>
<li>Consistently underestimate the effort required to wash dishes,
    clean clothes,
and keep the CI/CD pipeline running</li>
</ul>
</li>
<li><a href="https://allcontributors.org/">All Contributors</a> is a way to recognize
    &ldquo;other&rdquo; contributions to code</li>
<li>Though &ldquo;recognize&rdquo; isn&rsquo;t the same as &ldquo;value&rdquo;</li>
</ul>
<hr />
<h2>One for All?</h2>
<ul>
<li>Should every team be assessed the same way?</li>
<li>Pro:<ul>
<li>Easier for instructor (a real consideration in a large course)</li>
<li>Makes inter-team comparison fairer</li>
</ul>
</li>
<li>Con:<ul>
<li>Forces projects to be similar enough to be comparable</li>
<li>Not how the real world works</li>
</ul>
</li>
</ul>
<hr />
<!--# class="aside" -->

<h2>Seeing Like a Prof</h2>
<ul>
<li><span class="bib-ref">[<a class="bib-ref" href="../bib/#Scott1999">Scott1999</a>]</span> argued that large organizations prefer uniformity over productivity</li>
<li>Individual differences require case-by-case attention</li>
<li>But that doesn&rsquo;t scale<ul>
<li>&ldquo;How can you govern a country which has 246 varieties of cheese?&rdquo; (Charles de Gaulle)</li>
</ul>
</li>
<li>Central control isn&rsquo;t always bad<ul>
<li>&ldquo;States&rsquo; rights&rdquo; was and is a euphemism for &ldquo;legalized racism&rdquo;</li>
</ul>
</li>
<li>&ldquo;Politics&rdquo; is often considered a dirty word,
    but every organization continually renegotiates the boundary between &ldquo;we decide&rdquo; and &ldquo;you decide&rdquo;</li>
</ul>
<hr />
<h2>Gaming the Rules</h2>
<blockquote>
<p>When a measure becomes a target, it ceases to be a good measure.</p>
<p>— <a href="https://en.wikipedia.org/wiki/Goodhart%27s_law">Charles Goodhart</a></p>
</blockquote>
<ul>
<li>Manager: &ldquo;We will evaluate you based on the number of bugs you close&rdquo;</li>
<li>Developer A: &ldquo;OK, I&rsquo;ll write &lsquo;em…&rdquo;</li>
<li>Developer B: &ldquo;…and I&rsquo;ll fix &lsquo;em…&rdquo;</li>
<li>Together: &ldquo;…and we&rsquo;ll split the money!&rdquo;</li>
</ul>
<hr />
<h2>Measuring Code</h2>
<ul>
<li>Lots of code metrics have been proposed<ul>
<li>Halstead&rsquo;s measures</li>
<li>Cyclomatic complexity</li>
<li>Many object-oriented measures</li>
</ul>
</li>
<li>But nothing works better than counting lines of code <span class="bib-ref">[<a class="bib-ref" href="../bib/#ElEmam2001">ElEmam2001</a>, <a class="bib-ref" href="../bib/#Herraiz2010">Herraiz2010</a>]</span><ul>
<li>Chances of a rule violation increase with the size of the code base</li>
<li>So <code>wc -l</code> is as accurate as anything else</li>
</ul>
</li>
</ul>
<hr />
<h2>Peer Evaluation</h2>
<ul>
<li>&ldquo;Rate your teammates&rsquo; work on a scale of 0 to 10.&rdquo;</li>
<li>If public, most people will give most of their teammates a 10<ul>
<li>The instructor doesn&rsquo;t have to live with the consequences of a 3</li>
<li>But the student who gave it does</li>
</ul>
</li>
<li>And if ratings are anonymous,
    people with lower social status will be given lower ratings <span class="fixme" markdown="1">citation</span></li>
<li>Even if people are honest, how do you ensure consistency?<ul>
<li>&ldquo;I wasn&rsquo;t trained to do this&rdquo;</li>
</ul>
</li>
</ul>
<hr />
<!--# class="aside" -->

<h2>Is It Actually A Problem?</h2>
<ul>
<li><span class="bib-ref">[<a class="bib-ref" href="../bib/#Kaufman2000">Kaufman2000</a>]</span> compared confidential peer ratings and grades in undergrad engineering courses<ul>
<li>Found that self-rating and peer ratings statistically agreed</li>
<li>And that collusion wasn&rsquo;t significant (i.e., people didn&rsquo;t just give everyone high grades)</li>
</ul>
</li>
<li>So why do we worry so much?<ul>
<li>Most people&rsquo;s mental model of disasters is <em>The Walking Dead</em></li>
<li>In fact, most people come together and help each other <span class="bib-ref">[<a class="bib-ref" href="../bib/#Solnit2010">Solnit2010</a>]</span> </li>
<li>But that doesn&rsquo;t make for as exciting a movie</li>
<li>And people are more likely to put up with restrictions on their freedoms
    if they are afraid of their neighbors</li>
</ul>
</li>
</ul>
<hr />
<h2>Calibrated Peer Review</h2>
<ul>
<li>Learner grades a piece of work based on a marking guide</li>
<li>Their evaluation is compared to the instructors&rsquo;</li>
<li>The learner&rsquo;s score is 100% minus points for:<ul>
<li>False negatives: missed a problem the instructor identified</li>
<li>False positives: thought something was a problem when it wasn&rsquo;t</li>
</ul>
</li>
<li>Learners&rsquo; evaluations will converge on the instructor&rsquo;s <span class="bib-ref">[<a class="bib-ref" href="../bib/#Pare2008">Pare2008</a>, <a class="bib-ref" href="../bib/#Kulkarni2013">Kulkarni2013</a>]</span></li>
<li>Which helps them review their peers code <em>and their own as they write it</em></li>
</ul>
<hr />
<!--# class="exercise" -->

<h2>Compare and Contrast</h2>
<ol>
<li>Have every person on the team review a program given by the instructor.</li>
<li>Compare reviews: where did you agree and disagree?</li>
<li>Repeat the exercise with another piece of code.
    Are your reviews closer to each other&rsquo;s?</li>
</ol>

  </body>
</html>
