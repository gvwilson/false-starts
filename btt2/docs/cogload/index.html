<!DOCTYPE html>
<html lang="en">
  <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="repo" content="https://github.com/gvwilson/btt">
  <link rel="icon" type="image/x-icon" href="../favicon.ico">
  <title>Building Tech Together: Cognitive Load</title>
  <link rel="stylesheet" href="../tango.css">
<link rel="stylesheet" href="../mccole.css">

<link rel="stylesheet" href="../pages.css">


  <script>
  MathJax = {
    tex: {
      inlineMath: [['\\(', '\\)']]
    }
  };
</script>
<script
  type="text/javascript"
  id="MathJax-script"
  async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>

  

</head>

  <body>
    <main data-slug="cogload">
      <div class="row title">
  <div class="col-1 left">
    <p>
      <a href="../"><img src="../codebender-logo.svg" alt="logo" class="logo"/></a>
    </p>
  </div>
  <div class="col-10 center">
    <h1>Cognitive Load</h1>
  </div>
  <div class="col-1"></div>
</div>


<div class="row notex">
  <div class="col-1 left">
    <a href="../intro/">&lArr;</a>
  </div>
  <div class="col-10 center">
    <span class="tagline">How our brains think constraints how we learn and collaborate.</span>
  </div>
  <div class="col-1 right">
    <a href="../meetings/">&rArr;</a>
  </div>
</div>
<ul class="syllabus">
<li>Our <strong>long-term memory</strong> is large but slow, and we don&rsquo;t have direct access to it.</li>
<li>Our <strong>short-term memory</strong> is fast but small: it can hold roughly 7±2 things at once.</li>
<li><strong>Cognitive load theory</strong> distinguishes between intrinsic, germane, and extraneous load.</li>
<li><strong>Chunking</strong> ideas together according to patterns effectively expands short-term memory.</li>
<li><strong>Novices</strong>, <strong>competent practitioners</strong>, and <strong>experts</strong> think differently and need to be taught differently.</li>
</ul>


      <p><a class="fig-ref" href="#cogload-architecture">Figure&nbsp;1</a> shows a very (very) simple model of
the cognitive architecture of the human brain.
On the left is long-term memory (LTM),
which is where you store things like the spelling of your name
and how that awful clown scared you when you were ten years old.
It is very large—you can keep adding to it as long as you live—but
you don&rsquo;t have direct conscious access to it.</p>
<figure id="cogload-architecture">
<img src="./cognitive-architecture.svg" alt="Cognitive architecture"/>
<figcaption markdown="1">Figure&nbsp;1: The cognitive architecture of the human mind (simplified).</figcaption>
</figure>

<p>Instead,
evolution has given you a second subsystem called short-term memory (STM) or working memory.
(More sophisticated models distinguish between these two concepts,
but this simple model is good enough for our needs.)
You are constantly fetching things from LTM into STM to use them,
then re-encoding them and writing them back to LTM.
This is one of the differences between your brain and a computer:
reading data from a hard drive doesn&rsquo;t alter it,
but every time you access something in LTM,
you may write it back in a different or augmented form.
We call this &ldquo;learning&rdquo;.</p>
<p>Here&rsquo;s the problem:
STM is very small.
<span class="bib-ref">[<a class="bib-ref" href="../bib/#Miller1956">Miller1956</a>]</span> estimated that it could hold 7±2 things at one time;
more modern estimates put the number closer to 4±1 <span class="bib-ref">[<a class="bib-ref" href="../bib/#Didau2016">Didau2016</a>]</span>.
This means that STM is a bottleneck for learning:
if too many new ideas are presented too quickly,
the new arrivals will knock older ones out of STM
before you have a chance to encode them and store them in LTM,
so learning won&rsquo;t take place.</p>
<p>This realization and others have produced the theory of cognitive load,
which (among other things) divides the things you have to do while learning
into three categories.
The intrinsic load is the thinking that is required by the learning task itself.
The germane (or relevant) load is the other thinking that the problem requires,
but which isn&rsquo;t the focus of the lesson,
while the extraneous load is everything you&rsquo;re being asked to do that is irrelevant.</p>
<p>For example,
suppose you are learning the grammar of Frisian.
If I ask you to translate,
&ldquo;How is her knee today?&rdquo;
then the intrinsic load is the rules of grammar,
but there is also the germane load of recalling vocabulary
(which is necessary, but isn&rsquo;t the main focus of the lesson).
If,
on the other hand,
I give you the words as shown in <a class="fig-ref" href="#cogload-frisian">Figure&nbsp;2</a>
and ask you to rearrange them,
I have eliminated the germane load,
but have added some extraneous load by using a mix of fonts.
You will solve the problem more quickly and more accurately
if the words are all in the same font,
no matter what that font is,
than if your brain is wondering whether the difference is significant.</p>
<figure id="cogload-frisian">
<img src="./cogload-frisian.svg" alt="Translating a sentence"/>
<figcaption markdown="1">Figure&nbsp;2: Reducing germane load while increasing extraneous load.</figcaption>
</figure>

<p>Cognitive load theory explains why tools like <a href="https://scratch.mit.edu/">Scratch</a> work so well:
they reduce germane load by getting rid of the commas, curly braces, and other distractions
so that learners can focus on mastering concepts like assignment and loops.
It also explains why working with code written in a mix of styles is so painful:
each minor difference adds extraneous load.</p>
<p>In order to handle larger sets of information,
our minds create chunks that only take up one slot in STM.
For example,
most of us remember words as single items rather than as sequences of letters.
Similarly,
the pattern made by five spots on cards or dice is remembered as a whole
rather than as five separate pieces of information.</p>
<p>Experts have more and larger chunks than non-experts,
i.e.,
experts &ldquo;see&rdquo; larger patterns and have more patterns to match things against.
This allows them to reason at a higher level
and to search for information more quickly and more accurately.
However,
chunking can also mislead us if we mis-identify things:
newcomers really can sometimes see things that experts have looked at and missed.</p>
<p>Given how important chunking is to thinking,
it is tempting to try to teach design patterns directly to learners as early as possible.
These patterns help competent practitioners think and talk to each other in many domains,
but pattern catalogs are too dry and too abstract for novices to make sense of on their own.
However, giving names to a small number of patterns does seem to help,
primarily by giving the learners a richer vocabulary to think and communicate with <span class="bib-ref">[<a class="bib-ref" href="../bib/#Sajaniemi2006">Sajaniemi2006</a>]</span>.</p>
<div class="fixme">
<ul>
<li>connect back to code comprehension</li>
<li>connect back to teamwork and org charts</li>
</ul>
</div>
    </main>
    <footer>
  <div class="row">
    <div class="col-1 left">
      <a href="../intro/">&lArr;</a>
    </div>
    <div class="col-10 center">
      <a href="../">Home</a>
      &middot;
      <a href="../license/">License</a>
      &middot;
      <a href="https://github.com/gvwilson/btt">Repository</a>
    </div>
    <div class="col-1 right">
      <a href="../meetings/">&rArr;</a>
    </div>
  </div>
</footer>

  </body>
</html>
