Three books changed my life as a programmer.
[%b Kernighan1981 %] taught me I could do more than just write software—I could *design* it—while
[%b Glass2002 %] taught me we could study software and software development scientifically
to determine what actually works (or doesn't).
In between them I read [%b Hunt1999 %];
for many programmers of my generation,
it was the first thing that described the craft of software construction
in a way that made sense.

I referred to those books over and over again
when I started teaching at the University of Toronto twenty years ago,
but re-reading them now I am struck by what they *don't* discuss.
Why are some people praised for trying and failing
while others are castigated for it?
What alternatives are there to Silicon Valley's destructive obsession with growth at any cost?
Who should be held responsible
when someone uses an AI model to create revenge porn or political misinformation?
The books I read when I was young didn't even ask these questions,
and neither do newer ones like [%b Larson2019 Orosz2023 Thomas2019 %],
but [%b Bullock2021 Cohen2021 Ferreira2021 Gordon2021 Prioleau2021 Rankin2021 %]
are a sign that these issues are starting to appear in the curriculum.

I hope your journey won't stop here.
As a programmer you are able to shape the world
in ways that most mad scientists can only dream of,
but as [%b Lee1962 %] said,
with great power comes great responsibility.
If you'd like to understand what my generation got wrong
so that you can avoid making the same mistakes,
ask your instructor to accept a report on one of these books for part of your project grade:

-   [%b Eubanks2019 %] shows how the algorithms used to allocate health care,
    target people for tax audits,
    and decide where police will patrol all punish the poor for being poor.
    (And if your reaction is, "Why should I care? I'm not poor,"
    talk to someone whose credit rating has never recovered
    from someone else with the same name missing a few student loan payments.)

-   [%b Noble2018 %] looks at how those algorithms
    and the ones used by search engines
    amplify and perpetuate racism and sexism.

-   [%b ONeil2017 %] delves more deeply into the math being used and abused by these systems.
    For example,
    software that predicts how likely someone is to commit a crime
    may use the age of their first interaction with the police in its score.
    Thanks to racially biased policing practices,
    Black men are likely to have that encounter earlier than white men.
    The Black man is therefore more likely to receive a prison sentence,
    which increases the chance of a future offense,
    which is then used as evidence that the algorithm works.

-   [%b WachterBoettcher2017 CriadoPerez2019 %] look at
    how the lack of diversity among engineers and managers
    leads to products that either don't address everyone's needs
    or actually do harm:
    seatbelts and airbags that injure women because they were only tested on male models,
    facial recognition systems that don't recognize Black faces,
    and "where's my phone?" apps
    that help abusive domestic partners keep tabs on their victims.

I hope that using time management and team structure
as a way to ease you into more important topics
has given you something to think about.
I realize that change is hard and takes time,
but if we don't find a way to fix the tech industry
our lives are going to keep getting worse.
I wish you luck.

<div class="center" markdown="1">
  Start where you are.
  <br/>
  Use what you have.
  <br/>
  Help who you can.
</div>
